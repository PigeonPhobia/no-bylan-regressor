{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bacd7d0c-727e-44da-a7b2-8bbd120ee5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70507c4-b85b-415a-b4bf-388f8a5817fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93644c43-3051-4c90-828d-a389bfc4d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/'\n",
    "IMG_DIR = './img/'\n",
    "PROCESSED_DATA_DIR = './processed_data/'\n",
    "TRAIN_FILE = DATA_DIR + 'train.csv'\n",
    "TEST_FILE = DATA_DIR + 'train.csv'\n",
    "PROCESSED_TRAIN_FILE = PROCESSED_DATA_DIR + 'processed_train.csv'\n",
    "AUX_DATA_DIR = DATA_DIR + 'auxiliary-data/'\n",
    "SUBZONE_FILE = AUX_DATA_DIR + 'sg-subzones.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f7c554-9049-40fd-a89f-624902dd358d",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aad8088-cbc2-4540-8b78-58556a260c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(PROCESSED_TRAIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbdf8653-0171-448d-b34c-7b64a2d0ed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 1.00000000e+00 3.00000000e+00 ... 1.41439935e+00\n",
      "  1.03837196e+02 5.68125814e+02]\n",
      " [0.00000000e+00 2.00000000e+00 4.00000000e+00 ... 1.37259680e+00\n",
      "  1.03875625e+02 6.09170390e+02]\n",
      " [2.00000000e+00 5.00000000e+00 4.00000000e+00 ... 1.29877260e+00\n",
      "  1.03895798e+02 2.66465939e+03]\n",
      " ...\n",
      " [2.00000000e+00 5.00000000e+00 4.00000000e+00 ... 1.31596110e+00\n",
      "  1.03836848e+02 2.61727856e+03]\n",
      " [0.00000000e+00 4.00000000e+00 3.00000000e+00 ... 1.44075330e+00\n",
      "  1.03806671e+02 5.40439333e+02]\n",
      " [2.00000000e+00 5.00000000e+00 4.00000000e+00 ... 1.31596110e+00\n",
      "  1.03836848e+02 2.61727856e+03]]\n",
      "[ 514500.  995400. 8485000. ... 4193700.  754800. 4178000.]\n"
     ]
    }
   ],
   "source": [
    "df_X = df_train.iloc[:,0:8]\n",
    "df_y = df_train.iloc[:,8]\n",
    "X, y = df_X.to_numpy(), df_y.to_numpy()\n",
    "\n",
    "# Split dataset in training and test data (20% test data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97a4a60-cc15-4cca-a897-36322475558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exhaustive_search(name, estimator, parameters, n_jobs=-1):\n",
    "    # define GridSearchCV\n",
    "    rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "    clf = GridSearchCV(estimator, parameters, scoring=rmse_scorer, verbose=4, n_jobs=n_jobs)\n",
    "    model = clf.fit(X_train, y_train)\n",
    "\n",
    "    # Store the parameters of the best model\n",
    "    best_params = model.best_params_\n",
    "\n",
    "    # Predict class labels of test data on the model with the best found parameters\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "\n",
    "    # Calculate the loss\n",
    "    best_loss = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    best_loss_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "\n",
    "    print('Best {} regressor: {}'.format(name, best_params))\n",
    "    print('RSME Loss: Train - {:.3f}, Test - {:.3f}'.format(best_loss_train, best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "030f9778-0b3f-4f9f-882a-3d6f349905ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection_dict = {\n",
    "    'AdaBoost': {\n",
    "        'estimator': AdaBoostRegressor(random_state=42),\n",
    "        'parameters': {\n",
    "            'base_estimator': [DecisionTreeRegressor(max_depth=3), DecisionTreeRegressor(max_depth=4), DecisionTreeRegressor(max_depth=5)],\n",
    "            'n_estimators': [400, 600, 800, 1000],\n",
    "            'learning_rate': [1e-1, 1e-2, 1e-3, 1e-4]\n",
    "        }\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'estimator': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "        'parameters': {\n",
    "            'n_estimators': [100, 200, 300, 400, 1000],\n",
    "            'max_depth': [10, 20, 30],\n",
    "            'min_samples_split': [2, 4, 6],\n",
    "            'max_features': [0.2, 0.6, 1.0],\n",
    "            'max_samples': [0.2, 0.6, 1.0]\n",
    "        }\n",
    "    },\n",
    "    'ExtraTrees': {\n",
    "        'estimator': ExtraTreesRegressor(bootstrap=True, random_state=42, n_jobs=-1),\n",
    "        'parameters': {\n",
    "            'n_estimators': [100, 200, 300, 400, 1000],\n",
    "            'max_depth': [10, 20, 30],\n",
    "            'min_samples_split': [2, 4, 6],\n",
    "            'max_features': [0.2, 0.6, 1.0],\n",
    "            'max_samples': [0.2, 0.6, 1.0]\n",
    "        }\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'estimator': GradientBoostingRegressor(random_state=42),\n",
    "        'parameters': {\n",
    "            'n_estimators': [100, 200, 300, 400, 1000],\n",
    "            'learning_rate': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'max_features': [0.2, 0.6, 1.0]\n",
    "        }\n",
    "    },\n",
    "    'DecisionTree': {\n",
    "        'estimator': DecisionTreeRegressor(random_state=42),\n",
    "        'parameters': {\n",
    "            'criterion': ['squared_error', 'friedman_mse']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d686910f-387d-41ed-8152-ae140c98b086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# for name, data in model_selection_dict.items():\n",
    "#     exhaustive_search(name, data['estimator'], data['parameters'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
